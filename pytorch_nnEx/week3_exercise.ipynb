{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "%matplotlib inline"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Convolutional Neural Network\n",
                "=====================\n",
                "\n",
                "In this exercise, you will practice how to impelement a convolutional neural network (CNN) for image classification with PyTorch. Specifically, you need to implement one of the most famous CNN - the LeNet, and apply it on a handwritten digits dataset - MNIST. After finishing building the network, you also need to run the training algorithm and compare the performance of LeNet and a multi-layer perceptron (We've already implemented for you). You can also do some hyperparameter tuning or model modification to check how it will affect the classification performance.\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "Training an image classifier\n",
                "----------------------------\n",
                "\n",
                "Normally, the algorithm for training a image classifier includes the  following steps:\n",
                "\n",
                "1. Load and normalize the training and test datasets using ``torchvision``\n",
                "2. Define a neural network model\n",
                "3. Define a loss function and optimizer\n",
                "4. Train the network on the training data\n",
                "5. Validate the network on the validation data\n",
                "6. Test the network on the test data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Hyperparameters\n",
                "\n",
                "After you finish building the neural network model, you can try different values of hyperparameters and check how it will affect the performance of your model, e.g., increase/decrease batch size and learning_rate, or increase the width of the convolutional layers."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: try different values of hyperparameters and check how it will affect the classification performance.\n",
                "\n",
                "batch_size=128\n",
                "learning_rate=0.0001"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Torchvision and datasets\n",
                "----------------\n",
                "\n",
                "PyTorch has a package called\n",
                "``torchvision``, which includes data loaders for common datasets such as\n",
                "Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz.,\n",
                "``torchvision.datasets`` and ``torch.utils.data.DataLoader``.\n",
                "\n",
                "This provides a huge convenience and avoids writing boilerplate code. For this exercise, we will use the MNIST dataset which is a large database of handwritten digits.\n",
                "\n",
                "The output of torchvision datasets are PILImage images of range [0, 1].\n",
                "We transform them to Tensors of normalized range [-1, 1]."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# We normalize the data by its mean and variance.\n",
                "transform=transforms.Compose([\n",
                "    transforms.ToTensor(),\n",
                "    transforms.Normalize((0.1307,), (0.3081,))\n",
                "    ])\n",
                "\n",
                "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
                "                                download=True, transform=transform)\n",
                "\n",
                "\n",
                "# training validation split \n",
                "train_set, val_set = torch.utils.data.random_split(trainset, [50000, 10000])\n",
                "\n",
                "\n",
                "trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
                "                                          shuffle=True, num_workers=2)\n",
                "\n",
                "valloader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,\n",
                "                                          shuffle=False, num_workers=2)\n",
                "\n",
                "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
                "                                download=True, transform=transform)\n",
                "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
                "                                         shuffle=False, num_workers=2)\n",
                "\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<div class=\"alert alert-info\"><h4>Note</h4><p>If running on Windows and you get a BrokenPipeError, try setting\n",
                "    the num_worker of torch.utils.data.DataLoader() to 0.</p></div>"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Build the LeNet\n",
                "----------------\n",
                "Build the network according to the instruction. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n"
                    ]
                }
            ],
            "source": [
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "\n",
                "# TODO: Implement the LeNet according to the description.\n",
                "class LeNet(nn.Module):\n",
                "\n",
                "    def __init__(self):\n",
                "        super(LeNet, self).__init__()\n",
                "        # Here is an example of the convolutional layer where \n",
                "        # input channel=1, output channel=6, kernel size=5, padding=2\n",
                "        # for this layer (only) we set padding=2 because LeNet is\n",
                "        # expecting an image of size 32x32 instead of 28x28 (MNIST Image size)\n",
                "        # implement other layers by yourself.\n",
                "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
                "        print(self.conv1)\n",
                "        self.pool2 = nn.MaxPool2d(2)\n",
                "        self.conv3 = nn.Conv2d(6, 16, 5)\n",
                "        self.pool4 = nn.MaxPool2d(2)\n",
                "        self.linear5 = nn.Linear(400 , 120)\n",
                "        self.linear6 = nn.Linear(120, 84)\n",
                "        self.linear7 = nn.Linear(84, 10)\n",
                "\n",
                "    def forward(self, x):\n",
                "        convolution1 = self.pool2(F.relu(self.conv1(x)))\n",
                "        convolution2 = self.pool4(F.relu(self.conv2(convolution1)))\n",
                "        # flatten \n",
                "        convolution2 = convolution2.view(-1, )\n",
                "        out = F.relu(self.linear5(convolution2))\n",
                "        out = F.relu(self.linear6(out))\n",
                "        out = self.linear7(out)\n",
                "        return out\n",
                "# We've implemented a multi-layer perceptron model so that you can try to run the training algorithm\n",
                "# and compare it with LeNet in terms of the classification performance.\n",
                "class MLP(nn.Module):\n",
                "\n",
                "    def __init__(self):\n",
                "        super(MLP, self).__init__()\n",
                "        self.input = nn.Linear(28 * 28, 512)\n",
                "        self.hidden = nn.Linear(512, 256)\n",
                "        self.output = nn.Linear(256, 10)\n",
                "    \n",
                "    def forward(self, x):\n",
                "        x = x.view(-1, 28 * 28)\n",
                "        x = torch.sigmoid(self.input(x))\n",
                "        x = torch.sigmoid(self.hidden(x))\n",
                "        x = self.output(x)\n",
                "        return x\n",
                "\n",
                "net = MLP()\n",
                "\n",
                "# Uncomment this line after you implement it\n",
                "net = LeNet()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Loss Function and Optimizer\n",
                "----------------\n",
                "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.optim as optim\n",
                "\n",
                "criterion = nn.CrossEntropyLoss()\n",
                "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Training the network\n",
                "----------------\n",
                "\n",
                "This is when things start to get interesting.\n",
                "We simply have to loop over our data iterator, and feed the inputs to the\n",
                "network and optimize. After each epoch, we print the statistics.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "ename": "AttributeError",
                    "evalue": "'LeNet' object has no attribute 'conv2'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
                        "\u001b[1;32mc:\\Users\\khain\\Desktop\\2022_T3\\9444\\pytorch_Ex\\pytorch_nnEx\\week3_exercise.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m outputs \u001b[39m=\u001b[39m net(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
                        "File \u001b[1;32mc:\\Users\\khain\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "\u001b[1;32mc:\\Users\\khain\\Desktop\\2022_T3\\9444\\pytorch_Ex\\pytorch_nnEx\\week3_exercise.ipynb Cell 14\u001b[0m in \u001b[0;36mLeNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     convolution1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool2(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1(x)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     convolution2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool4(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(convolution1)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     \u001b[39m# flatten \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/khain/Desktop/2022_T3/9444/pytorch_Ex/pytorch_nnEx/week3_exercise.ipynb#X16sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     convolution2 \u001b[39m=\u001b[39m convolution2\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, )\n",
                        "File \u001b[1;32mc:\\Users\\khain\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1184\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1185\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1186\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
                        "\u001b[1;31mAttributeError\u001b[0m: 'LeNet' object has no attribute 'conv2'"
                    ]
                }
            ],
            "source": [
                "for epoch in range(10):  # loop over the dataset multiple times\n",
                "    \n",
                "    train_loss = 0.0\n",
                "    train_acc = 0.0\n",
                "    val_loss = 0.0\n",
                "    val_acc = 0.0\n",
                "    test_loss = 0.0\n",
                "    test_acc = 0.0\n",
                "    \n",
                "    for i, data in enumerate(trainloader, 0):\n",
                "        # get the inputs; data is a list of [inputs, labels]\n",
                "        inputs, labels = data\n",
                "\n",
                "        # zero the parameter gradients\n",
                "        optimizer.zero_grad()\n",
                "\n",
                "        \n",
                "        \n",
                "        # forward + backward + optimize\n",
                "        outputs = net(inputs)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        \n",
                "        \n",
                "        \n",
                "        # statistics\n",
                "        train_loss += loss.item()\n",
                "        pred = torch.max(outputs, 1)[1]\n",
                "        train_correct = (pred == labels).sum()\n",
                "        train_acc += train_correct.item()\n",
                "\n",
                "        \n",
                "    # To get the best learned model, we need to do some statisticcs.\n",
                "    # After training, we pick the model with best validation accuracy.\n",
                "    with torch.no_grad():\n",
                "        net.eval()\n",
                "\n",
                "        for inputs, labels in valloader:\n",
                "\n",
                "            predicts = net(inputs)\n",
                "\n",
                "            loss = criterion(predicts, labels)\n",
                "            val_loss += loss.item()\n",
                "            pred = torch.max(predicts, 1)[1]\n",
                "            val_correct = (pred == labels).sum()\n",
                "            val_acc += val_correct.item()\n",
                "\n",
                "        for inputs, labels in testloader:\n",
                "\n",
                "            predicts = net(inputs)\n",
                "            pred = torch.max(predicts, 1)[1]\n",
                "            test_correct = (pred == labels).sum()\n",
                "            test_acc += test_correct.item()\n",
                "\n",
                "        net.train()\n",
                "    print(\"Epoch %d\" % epoch )\n",
                "\n",
                "    print('Training Loss: {:.6f}, Training Acc: {:.6f}, Validation Acc: {:.6f}, Test Acc: {:.6f}'.format(train_loss / (len(train_set))*32,train_acc / (len(train_set)), val_acc / (len(val_set)),test_acc / (len(testset))))        \n",
                "\n",
                "print('Finished Training')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.12 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "vscode": {
            "interpreter": {
                "hash": "a0cef5a626a259bdb0db6de645816e334ce0266e02748ac93db6e0e0b91b8047"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
